{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e38a0b46",
   "metadata": {},
   "source": [
    "## Accelerating Metal-Organic Framework Discovery via Synthesisability Prediction: The MFD Evaluation Method for One-Class Classification Models\n",
    "\n",
    "Chi Zhang, Dmytro Antypov, Matthew J. Rosseinsky, and Matthew S. Dyer*<br/>\n",
    "Email: M.S.Dyer@liverpool.ac.uk <br/>\n",
    "\n",
    "Please cite the corresponding paper if you used the Maximum Fractional Difference (MFD) method or these trained machine learning (ML) models in your work.\n",
    "\n",
    "### The Jupyter Notebook hereafter presents the code to predict the synthesisability of a [metal, linker] combination given by user\n",
    "\n",
    "This notebook requires the following input file from the `best_vs_poor_model` folder:<br/>\n",
    "`deep_model.tar` - the saved best-performing DeepSVDD model.<br/>\n",
    "\n",
    "and the following input file from current folder:<br/>\n",
    "`deep_scaler.joblib` - the saved DeepSVDD model scaler used to normalise the prediction score for the input.<br/>\n",
    "\n",
    "### Please input the [metal, linker] combination you would like to predict before calculation. Enter the metal as an element symbol and the organic linker as a SMILES string.\n",
    "\n",
    "Here we use ['Zr', 'O=C(O)CCC(=O)Nc1ccc(C(=O)O)cc1'] as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8badbb1",
   "metadata": {},
   "source": [
    "### Import training score and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52a87bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import nan as NaN\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import datasets, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5039098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ANACONDA3\\2021.05\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#import the trained DeepSVDD model\n",
    "import sys\n",
    "paths = ['model_architecture/Deep-SVDD-PyTorch/', 'model_architecture/Deep-SVDD-PyTorch/src', 'model_architecture/set_transformer/']\n",
    "sys.path.extend(paths)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from modules import SAB, PMA, ISAB\n",
    "import deepSVDD\n",
    "from base.base_net import BaseNet\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "        \n",
    "def build_autoencoder(net_name):\n",
    "    return PairsAutoEncoder()\n",
    "\n",
    "def build_network(net_name):  \n",
    "    return PairsEncoder()\n",
    "\n",
    "INPUT_DIM = 2253\n",
    "\n",
    "class PairsEncoder(BaseNet):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rep_dim = 100\n",
    "        self.seq = nn.Sequential(SAB(dim_in=2253, dim_out=1000, num_heads=10),\n",
    "            SAB(dim_in=1000, dim_out=500, num_heads=10),\n",
    "            SAB(dim_in=500, dim_out=100, num_heads=10),\n",
    "            PMA(dim=100, num_heads=5, num_seeds=1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "      x = torch.split(x, 2253, dim=1)     \n",
    "      x= torch.stack(x).transpose(0,1) \n",
    "      return self.seq(x).squeeze()\n",
    "\n",
    "class PairsAutoEncoder(BaseNet):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = PairsEncoder()\n",
    "        self.encoder.apply(init_weights)\n",
    "        self.decoder = nn.Sequential(nn.Linear(in_features=100, out_features=2253), nn.Sigmoid())\n",
    "        self.decoder.apply(init_weights)\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "#load deep model\n",
    "net_name = 'mof_Net'\n",
    "clf_deep = deepSVDD.DeepSVDD()\n",
    "clf_deep.net = build_network(net_name)\n",
    "clf_deep.ae_net = build_autoencoder(net_name)\n",
    "clf_deep.net_name = net_name\n",
    "clf_deep.load_model(model_path='best_vs_poor_model/deep_model.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc6a33",
   "metadata": {},
   "source": [
    "# Get the input and generate metal + linker features for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "088990cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the input with single metal and linker (SMILES string)\n",
    "metal = 'Zr' # sample, please input your combination\n",
    "linker = 'O=C(O)CCC(=O)Nc1ccc(C(=O)O)cc1' #sample, please input your combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b35f5992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate metal features for the input\n",
    "metal_scaled = pd.read_csv('dataset_generation_and_featurization/metal_scaled_205.csv', index_col=0)\n",
    "metal_df = metal_scaled.loc[metal,:]\n",
    "\n",
    "#generate linker features for the input\n",
    "import rdkit\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "mol = Chem.MolFromSmiles(linker)\n",
    "linker_modified = Chem.MolToSmiles(mol)\n",
    "fpts_dl = AllChem.GetMorganFingerprintAsBitVect(mol,3,2048)\n",
    "linker_df_dl = np.array(fpts_dl) # linker features to be used in deep model\n",
    "\n",
    "#concatenate metal features & linker features\n",
    "df_dl = np.concatenate((metal_df.to_numpy(), linker_df_dl)) # to be used in deep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17ec94e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "'''\n",
    "#DeepSVDD model scaler\n",
    "deep_train = pd.read_csv('one_class_classification_models/DeepSVDD_train.csv', index_col=0)\n",
    "deep_test = pd.read_csv('one_class_classification_models/DeepSVDD_test.csv', index_col=0)\n",
    "deep_range = np.concatenate((deep_train,deep_test)).reshape(-1,1)\n",
    "\n",
    "MinMax_scaler = preprocessing.MinMaxScaler()\n",
    "deep_scaler = MinMax_scaler.fit(np.array(deep_range).reshape(-1,1))\n",
    "\n",
    "#save deep_scaler\n",
    "dump(deep_scaler, 'deep_scaler.joblib')\n",
    "'''\n",
    "\n",
    "#load deep_scaler\n",
    "deep_scaler = load('deep_scaler.joblib')\n",
    "\n",
    "device = 'cpu'\n",
    "def score(deep_SVDD, X):\n",
    "    with torch.no_grad():\n",
    "        net = deep_SVDD.net.to(device)\n",
    "        X = torch.FloatTensor(X).to(device)\n",
    "        y = net(X)\n",
    "        c, R = torch.FloatTensor([deep_SVDD.c]).to(device), torch.FloatTensor([deep_SVDD.R]).to(device)\n",
    "        dist = torch.sum((y - c)**2, dim=1)\n",
    "        if deep_SVDD.objective == 'soft-boundary':\n",
    "            scores = dist - R ** 2\n",
    "        else:\n",
    "            scores = dist\n",
    "    return scores\n",
    "\n",
    "output_deep = score(clf_deep, df_dl.reshape(1,-1)).cpu().detach().numpy()*(-1)\n",
    "output_deep = deep_scaler.transform(output_deep.reshape(-1,1)) \n",
    "output_deep = np.round(output_deep[0][0], 3)\n",
    "output_deep_predict = output_deep > 0.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd737db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The normalised prediction score for your input is:  0.618\n",
      "Our model predicts the synthesisability of the input combination is:  False\n"
     ]
    }
   ],
   "source": [
    "#output score\n",
    "print('The normalised prediction score for your input is: ', output_deep)\n",
    "#output prediction, True represent synthesisable while False represent not synthesisable (by the model)\n",
    "print('Our model predicts the synthesisability of the input combination is: ', output_deep_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "271.317px",
    "left": "1105px",
    "right": "20px",
    "top": "-38px",
    "width": "543.233px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
